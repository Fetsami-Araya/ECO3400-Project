{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "talented-berkeley",
   "metadata": {},
   "source": [
    "## Lasso and Spline Implementation\n",
    "\n",
    "-Sam Kirsh, March 20, 2021 //\n",
    "ECO3400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "geological-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV #Can use these last three functions for both Ridge and\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import os\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\Sam Kirsh\\\\ECO3400-Project\\\\data')\n",
    "\n",
    "data = read_csv('master_data_no_na.csv', header = 0, index_col = 0)\n",
    "X = data.values\n",
    "\n",
    "y = X[:,2]\n",
    "#Now, define the model\n",
    "def lasso(alpha, X, y):\n",
    "    mod = Lasso(alpha, max_iter = 10000)\n",
    "    lassofit = mod.fit(X,y)\n",
    "    return lassofit\n",
    "\n",
    "\n",
    "#Need to tune the model by cross validation -- important to note that we need to partition the data appropriately.\n",
    "#In this case we should conduct CV with a training, validation set. Of total data length of ~7000 series, take 750 for CV. \n",
    "lassocrossval = RepeatedKFold(n_splits = 10, n_repeats=3)\n",
    "\n",
    "#Search for hyperparameter via grid search\n",
    "#CV for hyperparameter\n",
    "grid = dict() \n",
    "grid['alpha'] = np.arange(0,1,0.01) #Use dictionary structure for alphas; \n",
    "#Use GridSearchCV\n",
    "lasso_cv_search = GridSearchCV(lassomod, grid, scoring = 'neg_mean_absolute_error', n_jobs = -1)\n",
    "\n",
    "\n",
    "#Evaluate by scoring the cross validation:\n",
    "#lasso_score = cross_val_score(lassomod, data(x), data(y), scoring = 'neg_mean_absolute_error', cv = lassocrossval, n_jobs = -1)\n",
    "\n",
    "#Do we need to force scores positive?\n",
    "#In any case, print them out\n",
    "#print(lasso_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "satellite-provision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.89853647e-03  2.59990217e-03  9.95935809e-01  9.32507405e-04\n",
      "  4.30012911e-03  3.45128070e-04  3.29862853e+01  4.39181731e-03\n",
      "  1.48169301e+01 -4.37415856e+00 -3.44186305e-01 -9.06860135e-04\n",
      " -4.74089132e+01  3.35657877e-05 -4.56132169e-07 -2.80619596e-04\n",
      "  1.06285358e+00  1.06294605e+00 -1.09338139e-03  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  2.01026530e+01 -9.32029727e-04]\n"
     ]
    }
   ],
   "source": [
    "#Test the lasso function\n",
    "mod = lasso(1, X, y)\n",
    "print(mod.coef_) #Check! It works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "present-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the spline regression, import necessary libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "#Thankfully already have the other functions from the previous panel\n",
    "\n",
    "#Specify Ridge model\n",
    "def ridge(alpha, X, y):\n",
    "    mod = Ridge(alpha, max_iter = 10000, normalize = True) #Dealing with both large and small values, hence the normalization\n",
    "    ridge_mod = mod.fit(X,y)\n",
    "    return ridge_mod\n",
    "\n",
    "#Run cross validation\n",
    "ridge_crossval = RepeatedKFold(n_splits = 10, n_repeats = 3)\n",
    "\n",
    "#CV for hyperparameter\n",
    "grid = dict() \n",
    "grid['alpha'] = np.arange(0,1,0.01) #Use dictionary structure for alphas; \n",
    "#Use GridSearchCV\n",
    "#GridSearchCV(ridgemod, grid, scoring = 'neg_mean_absolute_error', cv = ridge_crossval, n_jobs = -1)\n",
    "\n",
    "#Ridge search\n",
    "#ridge_grid = search.fit(Data(x), data(y)) #We would have already separated our data here into their proper structure. \n",
    "#Now that we have tuned the hyperparameter (if this is indeed the correct order) score the Ridge model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "informational-marsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.02101899e-02  9.63547332e-02  6.86698127e-02  3.66052686e-02\n",
      "  9.94194698e-02  2.56820800e-03  4.11179423e+03  2.12366023e+00\n",
      "  4.46029225e+02  5.91848046e+02  1.08974205e+02  4.24738483e-01\n",
      " -4.01549292e+03  6.58383300e-04  1.06259086e-03 -1.53027888e-01\n",
      "  4.34797919e+01 -2.86503252e+02  1.81537907e+00 -2.12690224e+04\n",
      " -3.64518325e+03 -9.86910899e+02 -1.91817712e+02  2.38169882e-02]\n"
     ]
    }
   ],
   "source": [
    "rmod = ridge(1, X, y)\n",
    "print(rmod.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-south",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
